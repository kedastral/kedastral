# Kedastral Multi-Workload Configuration Example
#
# This file demonstrates how to configure multiple workloads in a single
# forecaster instance. Each workload runs independently with its own
# forecast loop, model, and capacity planning policy.

workloads:
  # Example 1: HTTP API with baseline forecasting
  - name: web-api

    # Metric name (used in logs and snapshots)
    metric: http_requests_per_second

    # Adapter configuration
    adapter: prometheus
    adapterConfig:
      url: http://prometheus:9090
      query: sum(rate(http_requests_total{app="web-api"}[1m]))

    # Forecast parameters
    horizon: 30m      # How far ahead to predict (default: 30m)
    step: 1m          # Granularity of predictions (default: 1m)
    interval: 30s     # How often to generate forecasts (default: 30s)
    window: 1h        # Historical data window for training (default: 30m)

    # Model selection
    model: baseline   # Options: baseline, arima

    # Capacity planning policy
    targetPerPod: 100.0              # Target metric value per pod
    headroom: 1.2                     # Safety multiplier (1.2 = 20% headroom)
    minReplicas: 2                    # Minimum pod count
    maxReplicas: 50                   # Maximum pod count
    upMaxFactorPerStep: 2.0           # Max scale-up factor per forecast step
    downMaxPercentPerStep: 50         # Max scale-down percent per forecast step

  # Example 2: Queue-based worker with longer horizon
  - name: background-worker
    metric: queue_depth
    adapter: prometheus
    adapterConfig:
      url: http://prometheus:9090
      query: sum(rabbitmq_queue_messages{queue="tasks"})

    # Longer horizon for batch processing workloads
    horizon: 1h
    step: 5m
    interval: 1m
    window: 2h

    model: baseline
    targetPerPod: 50.0
    headroom: 1.5                     # Higher headroom for variable workloads
    minReplicas: 1                    # Can scale to zero during off-hours
    maxReplicas: 20
    upMaxFactorPerStep: 3.0           # Faster scale-up for queues
    downMaxPercentPerStep: 30         # Conservative scale-down

  # Example 3: Stream processor with ARIMA model
  - name: data-processor
    metric: processing_lag_seconds
    adapter: prometheus
    adapterConfig:
      url: http://prometheus:9090
      query: max(kafka_consumer_lag_seconds{topic="events"})

    # Short interval for real-time processing
    horizon: 15m
    step: 30s
    interval: 15s
    window: 30m

    # ARIMA model with custom parameters
    model: arima
    arimaP: 2         # Autoregressive order (0=auto)
    arimaD: 1         # Differencing order (0=auto)
    arimaQ: 1         # Moving average order (0=auto)

    targetPerPod: 60.0
    headroom: 1.3
    minReplicas: 3                    # Always keep minimum capacity
    maxReplicas: 100
    upMaxFactorPerStep: 2.5
    downMaxPercentPerStep: 40

# Notes:
# - Workload names must be DNS-compatible (alphanumeric, dash, underscore, 1-253 chars)
# - All durations use Go format: 30s, 5m, 1h, etc.
# - Adapter types: prometheus, victoriametrics, http
# - adapterConfig is a map of string key-value pairs specific to each adapter type
# - arimaP/arimaD/arimaQ are only used when model=arima
# - Set arimaP/D/Q to 0 for automatic parameter selection
